{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "298a8c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "#必要ライブラリの読み込み\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bf6a2ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image</th>\n",
       "      <th>brix</th>\n",
       "      <th>check</th>\n",
       "      <th>judge</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>bbrix1.JPG</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-ripe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>bbrix2-1.JPG</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotten</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>bbrix3.JPG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sweet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>bbrix4-1.JPG</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-ripe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>bbrix4-2.JPG</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-ripe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>n111.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sweet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>NaN</td>\n",
       "      <td>n112.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sweet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>n113.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sweet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>NaN</td>\n",
       "      <td>n114.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sweet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>NaN</td>\n",
       "      <td>n115.JPG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sweet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         image  brix check     judge  label\n",
       "0    1.0    bbrix1.JPG  17.0   NaN  non-ripe      0\n",
       "1    2.0  bbrix2-1.JPG  20.0   NaN    rotten      2\n",
       "2    4.0    bbrix3.JPG  22.0   NaN     sweet      1\n",
       "3    5.0  bbrix4-1.JPG  17.0   NaN  non-ripe      0\n",
       "4    6.0  bbrix4-2.JPG  17.0   NaN  non-ripe      0\n",
       "..   ...           ...   ...   ...       ...    ...\n",
       "122  NaN      n111.JPG   NaN   NaN     sweet      1\n",
       "123  NaN      n112.JPG   NaN   NaN     sweet      1\n",
       "124  NaN      n113.JPG   NaN   NaN     sweet      1\n",
       "125  NaN      n114.JPG   NaN   NaN     sweet      1\n",
       "126  NaN      n115.JPG   NaN   NaN     sweet      1\n",
       "\n",
       "[127 rows x 6 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの読み込みと編集\n",
    "data = pd.read_csv('banana_brix9.csv')  # CSVファイルに画像ファイル名とクラスラベルが含まれていると仮定\n",
    "# クラスラベルを整数にエンコードする辞書を作成\n",
    "label_encoding = {\n",
    "    'non-ripe': 0,\n",
    "    'sweet': 1,\n",
    "    'rotten': 2\n",
    "}\n",
    "\n",
    "# データフレームの'judge'列を整数にエンコードして新しい'label'列を作成\n",
    "data['label'] = data['judge'].map(label_encoding)\n",
    "\n",
    "# 'label'列が正しく追加されたことを確認\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c8dac18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "編集済みの画像を保存しました。\n"
     ]
    }
   ],
   "source": [
    "#バナナ検知モデルを使い、編集画像を保存する\n",
    "# モデルを読み込む\n",
    "model_d = joblib.load('bananaDetect3.pkl')\n",
    "# 画像フォルダのパス\n",
    "image_folder = 'banana_brix_images'\n",
    "edit_image_folder = 'banana_brix_images_edit'\n",
    "# デバイスの指定 (GPUが利用可能な場合はGPUを使用し、それ以外の場合はCPUを使用)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "# 1. 画像の前処理\n",
    "def preprocess_image(image):\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor(),  # 画像をテンソルに変換\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)  # バッチ次元を追加\n",
    "\n",
    "# 2. モデルに画像を渡して推論\n",
    "def predict(model, image_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        predictions = model(image_tensor)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# 画像フォルダ内の各画像に対して処理\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith('.JPG'):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        # 画像を開く\n",
    "        pil_image = Image.open(image_path)\n",
    "        # バウンディングボックスを検出\n",
    "        image_tensor = preprocess_image(pil_image)\n",
    "        predictions = predict(model_d, image_tensor)\n",
    "        \n",
    "        # しきい値を設定\n",
    "        threshold = 0.5  # この値を必要に応じて調整\n",
    "        # 最もスコアが高いバウンディングボックスを見つける\n",
    "        best_score = 0.0\n",
    "        best_box = None\n",
    "        for score, label, box in zip(predictions[0]['scores'], predictions[0]['labels'], predictions[0]['boxes']):\n",
    "            if score > threshold and score > best_score:\n",
    "                best_score = score\n",
    "                best_box = box\n",
    "\n",
    "        if best_box is not None:\n",
    "            best_box = [round(i, 2) for i in best_box.tolist()]\n",
    "            x1, y1, x2, y2 = map(int, best_box)\n",
    "            cropped_image = pil_image.crop((x1, y1, x2, y2))\n",
    "            # 画像を保存\n",
    "            edit_image_path = os.path.join(edit_image_folder, filename)\n",
    "            cropped_image.save(edit_image_path)\n",
    "\n",
    "print(\"編集済みの画像を保存しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b6d0dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#編集画像のパスと前処理\n",
    "# 画像フォルダのパス\n",
    "image_folder = 'banana_brix_images_edit'  # 保存した編集済み画像のフォルダ\n",
    "\n",
    "# 画像の前処理\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),  # 画像を指定のサイズにリサイズ\n",
    "    T.RandomHorizontalFlip(),  # ランダムな水平反転\n",
    "    T.RandomRotation(10),  # ランダムな回転（最大10度）\n",
    "    T.ToTensor(),  # 画像をテンソルに変換\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 画像を標準化\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5eae1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 除外するファイル名のリスト\n",
    "exclude_filenames = ['n20.JPG']\n",
    "# 'image' 列が特定のファイル名を持たない行を取り除く\n",
    "data = data[~data['image'].isin(exclude_filenames)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "404ee939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#データセットの設定\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_folder, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, str(self.dataframe.iloc[idx]['image']))  # 'image'列を文字列に変換\n",
    "        # ファイルの存在確認\n",
    "        if os.path.exists(img_name):\n",
    "            image = Image.open(img_name)\n",
    "            label = int(self.dataframe.iloc[idx]['label'])  # 'label'列を使用\n",
    "        else:\n",
    "            # ファイルが存在しない場合の処理を記述\n",
    "            print(f\"File not found: {img_name}\")\n",
    "            # 例外をスローする場合： raise FileNotFoundError(f\"File not found: {img_name}\")\n",
    "            # デフォルト画像を使用する場合： image = Image.open('default_image.jpg')\n",
    "            return None, None  # ダミーの値を返すことでスキップします\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7132229a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taisei_yamaguchi/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/taisei_yamaguchi/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "after\n",
      "Epoch [1/6] Loss: 5.615104966693455\n",
      "Epoch [2/6] Loss: 2.289085202746921\n",
      "Epoch [3/6] Loss: 1.7477173739009433\n",
      "Epoch [4/6] Loss: 1.2803681426578097\n",
      "Epoch [5/6] Loss: 1.2320668896039326\n",
      "Epoch [6/6] Loss: 1.0324179066552057\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "#分割しないでみる\n",
    "dataset=CustomDataset(data,image_folder,transform=transform)\n",
    "batch_size = 15\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# ニューラルネットワークモデルの定義 (例: ResNet)\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_classes = 3  # クラス数を指定\n",
    "\n",
    "# モデルの最終層を変更して、出力クラス数に合わせる\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Heの初期化を適用\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "# モデルの各層の重みを初期化\n",
    "print('before')\n",
    "model.apply(initialize_weights)\n",
    "print('after')\n",
    "\n",
    "# 損失関数とオプティマイザを定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# モデルの訓練\n",
    "num_epochs = 6  # エポック数を指定 (必要に応じて調整)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # エポックごとの損失を表示\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}] Loss: {running_loss / len(loader)}')\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "650f3637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for b53.JPG: 1\n",
      "Predicted class for b47.JPG: 1\n",
      "Predicted class for bbrix28.JPG: 1\n",
      "Predicted class for b52.JPG: 1\n",
      "Predicted class for b44.JPG: 1\n",
      "Predicted class for n48.JPG: 1\n",
      "Predicted class for b40.JPG: 1\n",
      "Predicted class for b43.JPG: 1\n",
      "Predicted class for bbrix4-1.JPG: 1\n",
      "Predicted class for bbrix11-1.JPG: 1\n",
      "Predicted class for n38.JPG: 1\n",
      "Predicted class for n39.JPG: 1\n",
      "Predicted class for b39.JPG: 1\n",
      "Predicted class for n35.JPG: 1\n",
      "Predicted class for n37.JPG: 1\n",
      "Predicted class for n36.JPG: 1\n",
      "Predicted class for n43.JPG: 1\n",
      "Predicted class for n42.JPG: 1\n",
      "Predicted class for b4.JPG: 1\n",
      "Predicted class for n40.JPG: 1\n",
      "Predicted class for n41.JPG: 1\n",
      "Predicted class for b3.JPG: 1\n",
      "Predicted class for n51.JPG: 1\n",
      "Predicted class for bbrix18-2.JPG: 1\n",
      "Predicted class for n50.JPG: 1\n",
      "Predicted class for n44.JPG: 1\n",
      "Predicted class for b49.JPG: 1\n",
      "Predicted class for b2.JPG: 1\n",
      "Predicted class for bbrix18-1.JPG: 1\n",
      "Predicted class for n52.JPG: 1\n",
      "Predicted class for b1.JPG: 1\n",
      "Predicted class for bbrix9-2.JPG: 1\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. モデルを読み込む\n",
    "model_d = joblib.load('bananaDetect3.pkl')\n",
    "\n",
    "# 2. 画像の前処理\n",
    "def preprocess_image(image):\n",
    "    transform_d = T.Compose([\n",
    "        T.ToTensor(),  # 画像をテンソルに変換\n",
    "    ])\n",
    "    return transform_d(image).unsqueeze(0)  # バッチ次元を追加\n",
    "\n",
    "# 3. モデルに画像を渡してバウンディングボックスを検出\n",
    "def detect_bounding_box(model, image_tensor, threshold=0.5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        predictions = model(image_tensor)\n",
    "\n",
    "    # しきい値を超える最もスコアの高いバウンディングボックスを見つける\n",
    "    best_score = 0.0\n",
    "    best_box = None\n",
    "    for score, label, box in zip(predictions[0]['scores'], predictions[0]['labels'], predictions[0]['boxes']):\n",
    "        if score > threshold and score > best_score:\n",
    "            best_score = score\n",
    "            best_box = box\n",
    "\n",
    "    return best_box\n",
    "\n",
    "\n",
    "\n",
    "#4. 切り取った画像に対する前処理を追加\n",
    "def preprocess_cropped_image(image):\n",
    "    transform = T.Compose([\n",
    "        T.Resize((224, 224)),  # 画像を指定のサイズにリサイズ\n",
    "        T.RandomHorizontalFlip(),  # ランダムな水平反転\n",
    "        T.RandomRotation(10),  # ランダムな回転（最大10度）\n",
    "        T.ToTensor(),  # 画像をテンソルに変換\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 画像を標準化\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)  # バッチ次元を追加\n",
    "\n",
    "# 5. 切り取った画像に対して分類を行う\n",
    "def classify_banana(model, image):\n",
    "    # 画像の前処理を適用\n",
    "    image_tensor = preprocess_image(image)\n",
    "    \n",
    "    #ここで、切り取り画像の前処理を行う。\n",
    "    \n",
    "    # モデルに画像を入力し、予測を取得\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "    \n",
    "    # 予測クラスの取得\n",
    "    _, predicted_class = outputs.max(1)\n",
    "    \n",
    "    return predicted_class.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 画像フォルダ内の各画像に対して処理\n",
    "image_folder = 'bananas_images_test'  # 画像フォルダのパスを指定\n",
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith('.JPG'):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        # 画像を開く\n",
    "        pil_image = Image.open(image_path)\n",
    "        # バウンディングボックスを検出\n",
    "        image_tensor = preprocess_image(pil_image)\n",
    "        bounding_box = detect_bounding_box(model_d, image_tensor)\n",
    "        \n",
    "        if bounding_box is not None:\n",
    "            # バウンディングボックス情報を取得\n",
    "            x1, y1, x2, y2 = map(int, bounding_box.tolist())\n",
    "            cropped_image = pil_image.crop((x1, y1, x2, y2))\n",
    "            \n",
    "            # 切り取り画像に前処理を適用\n",
    "            cropped_image_tensor = preprocess_cropped_image(cropped_image)\n",
    "            \n",
    "            \n",
    "            # 分類を実行\n",
    "            predicted_class = classify_banana(model, cropped_image)\n",
    "            \n",
    "            # 予測クラスを表示\n",
    "            print(f\"Predicted class for {filename}: {predicted_class}\")\n",
    "            \n",
    "            \n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6186b67d",
   "metadata": {},
   "source": [
    "# 真っ黒いバナナの画像を除いて学習？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd72d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434adc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
