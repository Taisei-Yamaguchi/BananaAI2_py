{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22a18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "\n",
    "# # モデルのロード\n",
    "# model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "# model.eval()\n",
    "\n",
    "# # 画像の前処理\n",
    "# image = Image.open(\"bananas_DL/b1.JPG\")\n",
    "# image.show()\n",
    "# # image_tensor = F.to_tensor(image).unsqueeze(0)\n",
    "\n",
    "# # 物体検出の実行\n",
    "# with torch.no_grad():\n",
    "#     predictions = model(image_tensor)\n",
    "\n",
    "# print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af325032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>file_size</th>\n",
       "      <th>file_attributes</th>\n",
       "      <th>region_count</th>\n",
       "      <th>region_id</th>\n",
       "      <th>region_shape_attributes</th>\n",
       "      <th>region_attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1.JPG</td>\n",
       "      <td>1865803</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'name': 'polygon', 'all_points_x': [1294, 114...</td>\n",
       "      <td>{\"banana\":\"banana\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b2.JPG</td>\n",
       "      <td>1443106</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'name': 'polygon', 'all_points_x': [2607, 229...</td>\n",
       "      <td>{\"banana\":\"banana\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b3.JPG</td>\n",
       "      <td>1391833</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b5.JPG</td>\n",
       "      <td>1483898</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b6.JPG</td>\n",
       "      <td>1415255</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'name': 'polygon', 'all_points_x': [1200, 101...</td>\n",
       "      <td>{\"banana\":\"banana\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  file_size file_attributes  region_count  region_id  \\\n",
       "0   b1.JPG    1865803              {}             1          0   \n",
       "1   b2.JPG    1443106              {}             1          0   \n",
       "2   b3.JPG    1391833              {}             0          0   \n",
       "3   b5.JPG    1483898              {}             0          0   \n",
       "4   b6.JPG    1415255              {}             1          0   \n",
       "\n",
       "                             region_shape_attributes    region_attributes  \n",
       "0  {'name': 'polygon', 'all_points_x': [1294, 114...  {\"banana\":\"banana\"}  \n",
       "1  {'name': 'polygon', 'all_points_x': [2607, 229...  {\"banana\":\"banana\"}  \n",
       "2                                                 {}                   {}  \n",
       "3                                                 {}                   {}  \n",
       "4  {'name': 'polygon', 'all_points_x': [1200, 101...  {\"banana\":\"banana\"}  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# CSVファイルの読み込み\n",
    "annotations = pd.read_csv(\"bananas_train_ano.csv\", converters={\"region_shape_attributes\": eval})\n",
    "\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36204c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     {'name': 'polygon', 'all_points_x': [1294, 114...\n",
      "1     {'name': 'polygon', 'all_points_x': [2607, 229...\n",
      "2                                                    {}\n",
      "3                                                    {}\n",
      "4     {'name': 'polygon', 'all_points_x': [1200, 101...\n",
      "5     {'name': 'polygon', 'all_points_x': [1561, 151...\n",
      "6     {'name': 'polygon', 'all_points_x': [1117, 121...\n",
      "7                                                    {}\n",
      "8     {'name': 'polygon', 'all_points_x': [1649, 193...\n",
      "9     {'name': 'polygon', 'all_points_x': [881, 1360...\n",
      "10                                                   {}\n",
      "11    {'name': 'polygon', 'all_points_x': [792, 1016...\n",
      "12    {'name': 'polygon', 'all_points_x': [1070, 117...\n",
      "13    {'name': 'polygon', 'all_points_x': [1082, 114...\n",
      "14                                                   {}\n",
      "15    {'name': 'polygon', 'all_points_x': [532, 479,...\n",
      "16    {'name': 'polygon', 'all_points_x': [1945, 213...\n",
      "17    {'name': 'polygon', 'all_points_x': [1041, 111...\n",
      "18                                                   {}\n",
      "19    {'name': 'polygon', 'all_points_x': [656, 769,...\n",
      "20    {'name': 'polygon', 'all_points_x': [1325, 127...\n",
      "21    {'name': 'polygon', 'all_points_x': [429, 708,...\n",
      "22    {'name': 'polygon', 'all_points_x': [1143, 146...\n",
      "23                                                   {}\n",
      "24    {'name': 'polygon', 'all_points_x': [1058, 907...\n",
      "25    {'name': 'polygon', 'all_points_x': [1023, 134...\n",
      "26                                                   {}\n",
      "27    {'name': 'polygon', 'all_points_x': [2140, 241...\n",
      "28                                                   {}\n",
      "29    {'name': 'polygon', 'all_points_x': [1373, 127...\n",
      "30    {'name': 'polygon', 'all_points_x': [970, 733,...\n",
      "31    {'name': 'polygon', 'all_points_x': [1750, 168...\n",
      "32    {'name': 'polygon', 'all_points_x': [1768, 195...\n",
      "33    {'name': 'polygon', 'all_points_x': [1472, 185...\n",
      "34    {'name': 'polygon', 'all_points_x': [1679, 215...\n",
      "35                                                   {}\n",
      "36    {'name': 'polygon', 'all_points_x': [1846, 224...\n",
      "37    {'name': 'polygon', 'all_points_x': [1478, 190...\n",
      "38    {'name': 'polygon', 'all_points_x': [1295, 138...\n",
      "39    {'name': 'polygon', 'all_points_x': [1222, 851...\n",
      "40    {'name': 'polygon', 'all_points_x': [1161, 956...\n",
      "41    {'name': 'polygon', 'all_points_x': [962, 865,...\n",
      "42                                                   {}\n",
      "43                                                   {}\n",
      "44    {'name': 'polygon', 'all_points_x': [934, 1230...\n",
      "45    {'name': 'polygon', 'all_points_x': [940, 1058...\n",
      "46                                                   {}\n",
      "47    {'name': 'polygon', 'all_points_x': [1712, 117...\n",
      "48    {'name': 'polygon', 'all_points_x': [1029, 108...\n",
      "49    {'name': 'polygon', 'all_points_x': [479, 704,...\n",
      "50                                                   {}\n",
      "51    {'name': 'polygon', 'all_points_x': [1111, 136...\n",
      "52    {'name': 'polygon', 'all_points_x': [1524, 130...\n",
      "53    {'name': 'polygon', 'all_points_x': [1064, 922...\n",
      "54                                                   {}\n",
      "55                                                   {}\n",
      "56                                                   {}\n",
      "57    {'name': 'polygon', 'all_points_x': [1927, 235...\n",
      "58    {'name': 'polygon', 'all_points_x': [1247, 148...\n",
      "Name: region_shape_attributes, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 画像ファイル名の列を取得\n",
    "image_files = annotations[\"filename\"]\n",
    "region_raw_data=annotations[\"region_shape_attributes\"]\n",
    "print(region_raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa86229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1294, 1149, 1433, 1500, 1089, 1258, 1784, 2135, 1954, 1585]\n"
     ]
    }
   ],
   "source": [
    "print(region_raw_data[0]['all_points_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b18c05e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      b1.JPG\n",
      "1      b2.JPG\n",
      "2      b3.JPG\n",
      "3      b5.JPG\n",
      "4      b6.JPG\n",
      "5      b7.JPG\n",
      "6      b9.JPG\n",
      "7     b11.JPG\n",
      "8     b12.JPG\n",
      "9     b13.JPG\n",
      "10    b14.JPG\n",
      "11    b15.JPG\n",
      "12    b16.JPG\n",
      "13    b17.JPG\n",
      "14    b18.JPG\n",
      "15    b19.JPG\n",
      "16    b20.JPG\n",
      "17    b21.JPG\n",
      "18    b22.JPG\n",
      "19    b23.JPG\n",
      "20    b24.JPG\n",
      "21    b26.JPG\n",
      "22    b27.JPG\n",
      "23    b28.JPG\n",
      "24    b29.JPG\n",
      "25    b30.JPG\n",
      "26    b31.JPG\n",
      "27    b33.JPG\n",
      "28    b35.JPG\n",
      "29    b36.JPG\n",
      "30    b37.JPG\n",
      "31    b38.JPG\n",
      "32    b39.JPG\n",
      "33    b40.JPG\n",
      "34    b41.JPG\n",
      "35    b42.JPG\n",
      "36    b43.JPG\n",
      "37    b44.JPG\n",
      "38    b45.JPG\n",
      "39    b46.JPG\n",
      "40    b47.JPG\n",
      "41    b49.JPG\n",
      "42    b50.JPG\n",
      "43    b51.JPG\n",
      "44    b52.JPG\n",
      "45    b53.JPG\n",
      "46    b54.JPG\n",
      "47    b55.JPG\n",
      "48    b56.JPG\n",
      "49    b58.JPG\n",
      "50    b59.JPG\n",
      "51    b60.JPG\n",
      "52    b61.JPG\n",
      "53    b62.JPG\n",
      "54    b63.JPG\n",
      "55    b65.JPG\n",
      "56    b67.JPG\n",
      "57    b68.JPG\n",
      "58    b69.JPG\n",
      "Name: filename, dtype: object\n",
      "[([1294, 1149, 1433, 1500, 1089, 1258, 1784, 2135, 1954, 1585], [623, 762, 1131, 2014, 2915, 3048, 2764, 1996, 1185, 907]), ([2607, 2292, 2359, 1627, 284, 550, 1597, 2516, 2933, 2619], [569, 623, 1125, 1863, 2171, 2637, 2667, 2195, 1373, 1077]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([1200, 1017, 1052, 1283, 1780, 2448, 3080, 3086, 2193, 1431], [1413, 1537, 1833, 2223, 2554, 2637, 2507, 2051, 2057, 1638]), ([1561, 1519, 1821, 2229, 2796, 3695, 3654, 2962, 2229, 1655], [2022, 2152, 2235, 1910, 1620, 1454, 1147, 946, 1129, 1667]), ([1117, 1212, 1620, 1981, 2406, 2607, 2572, 2211, 1561, 1188], [1555, 1744, 1579, 1525, 1638, 1608, 1413, 1129, 1171, 1354]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([1649, 1939, 2318, 2856, 3086, 3068, 2720, 2371, 2022, 1679], [1117, 1626, 1785, 1898, 1785, 1638, 1443, 1336, 899, 384]), ([881, 1360, 1839, 2229, 2554, 2672, 2702, 2312, 1732, 1401], [1236, 1283, 1348, 1732, 2111, 2028, 1513, 1041, 863, 934]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([792, 1016, 1439, 1833, 2498, 2589, 2462, 1893, 1403, 1034], [2268, 2431, 2195, 2129, 2316, 2123, 1863, 1657, 1669, 1869]), ([1070, 1171, 1797, 2388, 2773, 2891, 2921, 2495, 1910, 1490], [1543, 1815, 1744, 2034, 2401, 2318, 1803, 1407, 1188, 1236]), ([1082, 1147, 1360, 2187, 2867, 3051, 2714, 1921, 1478, 1277], [1058, 1372, 1821, 2057, 1886, 1525, 1419, 1508, 1176, 928]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([532, 479, 680, 1301, 1738, 1762, 1525, 1099, 780, 615], [804, 1041, 1383, 1519, 1324, 1141, 1046, 1065, 810, 514]), ([1945, 2134, 2258, 2424, 2578, 2601, 2459, 2087, 1986, 1862], [1383, 1466, 1602, 1892, 1850, 1531, 1312, 1188, 1212, 1301]), ([1041, 1117, 1981, 2838, 3352, 3725, 3541, 2832, 1898, 1277], [1312, 1632, 1673, 1998, 2554, 2235, 1525, 958, 715, 928]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([656, 769, 1644, 2187, 2631, 2944, 2909, 2453, 1549, 1029], [1448, 1679, 1762, 2057, 2578, 2507, 1945, 1431, 1106, 1176]), ([1325, 1276, 1391, 1675, 1796, 1681, 1851, 2050, 1833, 1609], [1597, 2147, 2528, 2643, 2589, 2026, 1458, 1204, 1077, 1337]), ([429, 708, 1276, 1651, 2341, 2353, 1996, 1306, 774, 454], [3175, 3260, 2413, 2153, 1887, 1591, 1385, 1621, 1972, 2643]), ([1143, 1464, 1500, 1264, 1597, 1978, 2262, 2153, 1760, 1331], [895, 1802, 2516, 3375, 3405, 3072, 2220, 1597, 986, 738]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([1058, 907, 956, 1246, 1627, 1754, 1591, 1579, 1851, 1488], [1433, 2014, 2643, 3211, 3260, 3078, 2335, 1796, 1179, 1022]), ([1023, 1342, 2323, 2820, 3535, 3624, 3441, 2714, 1850, 1224], [1785, 1821, 1774, 1898, 2247, 2099, 1549, 1188, 1117, 1395]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([2140, 2412, 2802, 3388, 3464, 3512, 2950, 2814, 2578, 2383], [1058, 1785, 2300, 2448, 2258, 2087, 1425, 704, 225, 290]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([1373, 1276, 1077, 1325, 1645, 1978, 1954, 1754, 1367, 1113], [1258, 2002, 2395, 2431, 2195, 1833, 1306, 744, 599, 714]), ([970, 733, 1011, 1638, 2276, 3045, 3287, 3157, 2069, 1443], [1017, 1307, 1720, 1992, 1951, 1626, 1176, 1041, 1307, 1206]), ([1750, 1685, 1750, 1921, 2028, 2300, 2507, 2607, 2347, 1975], [1549, 1697, 1768, 1744, 1691, 1697, 1821, 1667, 1443, 1419]), ([1768, 1951, 2146, 2300, 2442, 2489, 2365, 2040, 1803, 1709], [1614, 1673, 1868, 2241, 2176, 1945, 1632, 1431, 1437, 1525]), ([1472, 1850, 1992, 2069, 2235, 2383, 2205, 1845, 1567, 1413], [993, 1247, 1490, 1827, 1833, 1608, 1046, 798, 733, 828]), ([1679, 2158, 2524, 3210, 3411, 3482, 2773, 2034, 1685, 1519], [1094, 1295, 1525, 2530, 2519, 1738, 786, 603, 715, 881]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([1846, 2241, 2572, 2790, 3015, 3169, 2926, 2483, 1756, 1638], [1187, 1401, 1768, 2318, 2341, 2051, 1324, 893, 745, 1082]), ([1478, 1904, 2235, 2737, 2944, 2968, 2548, 1791, 1490, 1348], [1685, 1638, 1762, 2252, 2252, 1921, 1336, 1117, 1224, 1437]), ([1295, 1380, 1868, 2220, 2329, 2332, 2037, 1729, 1425, 1298], [1729, 1756, 1788, 2057, 2037, 1815, 1546, 1469, 1525, 1658]), ([1222, 851, 625, 766, 1129, 1693, 2258, 2339, 2125, 1710], [2314, 2266, 2415, 2657, 2754, 2693, 2306, 2060, 1863, 2133]), ([1161, 956, 992, 1270, 1706, 1718, 1482, 1724, 1639, 1452], [1730, 2141, 2945, 3453, 3574, 3411, 2552, 1742, 1548, 1518]), ([962, 865, 925, 1318, 2032, 1754, 1675, 2038, 1706, 1325], [1978, 2589, 3272, 4004, 4016, 3151, 2419, 1343, 1137, 1306]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([934, 1230, 2453, 3524, 3920, 3707, 3151, 2371, 1744, 1113], [1106, 1324, 1171, 1561, 1508, 857, 585, 378, 432, 714]), ([940, 1058, 1502, 2530, 3139, 2997, 2034, 1295, 964, 822], [1667, 1904, 2217, 2270, 1821, 1502, 1691, 1448, 1194, 1342]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([1712, 1179, 865, 1137, 1470, 2189, 2534, 2425, 2359, 2081], [1808, 2093, 2377, 2498, 2528, 2208, 1585, 1331, 1040, 1252]), ([1029, 1082, 1277, 1797, 2318, 2749, 2660, 2318, 1868, 1253], [1850, 2022, 2128, 2111, 1915, 1584, 1366, 1395, 1590, 1732]), ([479, 704, 1088, 1531, 1726, 1661, 1188, 999, 840, 638], [987, 1567, 1986, 2040, 1915, 1774, 1472, 1117, 609, 692]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([1111, 1360, 1714, 2607, 3618, 3754, 3470, 2519, 1780, 1324], [1407, 1525, 1502, 1549, 1945, 1691, 1135, 863, 893, 1200]), ([1524, 1300, 659, 901, 1699, 2455, 2407, 1978, 1566, 1397], [1736, 2613, 3695, 3943, 3804, 2504, 1282, 708, 593, 780]), ([1064, 922, 952, 1206, 2501, 3595, 3695, 2986, 2241, 1431], [1242, 1478, 1756, 1626, 1531, 2028, 1584, 1041, 881, 946]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ([1927, 2353, 2773, 3051, 3293, 2891, 2483, 1754, 1295, 1283], [1413, 1655, 2306, 2483, 2016, 1378, 958, 744, 916, 1289]), ([1247, 1484, 1768, 2465, 3175, 3234, 2465, 1886, 1443, 1236], [1253, 1561, 1744, 1856, 1679, 1348, 1312, 1111, 834, 840])]\n"
     ]
    }
   ],
   "source": [
    "# バウンディングボックス情報の取得\n",
    "bounding_boxes = []\n",
    "for shape_attr in region_raw_data:\n",
    "    if shape_attr:  # {}空でない場合のみ処理を行う\n",
    "        all_points_x = shape_attr[\"all_points_x\"]  # キーが存在しない場合は空のリストを返す\n",
    "        all_points_y = shape_attr[\"all_points_y\"]  # キーが存在しない場合は空のリストを返す\n",
    "        bounding_boxes.append((all_points_x, all_points_y))\n",
    "    else:\n",
    "        bounding_boxes.append(([0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,]))  # 欠損値の場合は空のリストを追加\n",
    "\n",
    "print(image_files) #これを使う\n",
    "print(bounding_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f7e92a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1089, 623, 2135, 3048], [284, 569, 2933, 2667], [0, 0, 0, 0], [0, 0, 0, 0], [1017, 1413, 3086, 2637], [1519, 946, 3695, 2235], [1117, 1129, 2607, 1744], [0, 0, 0, 0], [1649, 384, 3086, 1898], [881, 863, 2702, 2111], [0, 0, 0, 0], [792, 1657, 2589, 2431], [1070, 1188, 2921, 2401], [1082, 928, 3051, 2057], [0, 0, 0, 0], [479, 514, 1762, 1519], [1862, 1188, 2601, 1892], [1041, 715, 3725, 2554], [0, 0, 0, 0], [656, 1106, 2944, 2578], [1276, 1077, 2050, 2643], [429, 1385, 2353, 3260], [1143, 738, 2262, 3405], [0, 0, 0, 0], [907, 1022, 1851, 3260], [1023, 1117, 3624, 2247], [0, 0, 0, 0], [2140, 225, 3512, 2448], [0, 0, 0, 0], [1077, 599, 1978, 2431], [733, 1017, 3287, 1992], [1685, 1419, 2607, 1821], [1709, 1431, 2489, 2241], [1413, 733, 2383, 1833], [1519, 603, 3482, 2530], [0, 0, 0, 0], [1638, 745, 3169, 2341], [1348, 1117, 2968, 2252], [1295, 1469, 2332, 2057], [625, 1863, 2339, 2754], [956, 1518, 1724, 3574], [865, 1137, 2038, 4016], [0, 0, 0, 0], [0, 0, 0, 0], [934, 378, 3920, 1561], [822, 1194, 3139, 2270], [0, 0, 0, 0], [865, 1040, 2534, 2528], [1029, 1366, 2749, 2128], [479, 609, 1726, 2040], [0, 0, 0, 0], [1111, 863, 3754, 1945], [659, 593, 2455, 3943], [922, 881, 3695, 2028], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1283, 744, 3293, 2483], [1236, 834, 3234, 1856]]\n"
     ]
    }
   ],
   "source": [
    "# x,yの最小値、最大値を格納したバウンディングボックスをつくる\n",
    "bounding_boxes_minmax=[]\n",
    "for bounding_box in bounding_boxes:\n",
    "    box_x=bounding_box[0]\n",
    "    box_y=bounding_box[1]\n",
    "\n",
    "    # バウンディングボックスの形式に変換 [xmin, ymin, xmax, ymax]\n",
    "    xmin = min(box_x)\n",
    "    ymin = min(box_y)\n",
    "    xmax = max(box_x)\n",
    "    ymax = max(box_y)\n",
    "    bounding_boxes_minmax.append([xmin, ymin, xmax, ymax])\n",
    "print(bounding_boxes_minmax) #これを使う？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "70a5ff31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BananaDataset(Dataset):\n",
    "    def __init__(self, image_files, bounding_boxes_minmax, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.bounding_boxes_minmax = bounding_boxes_minmax\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_files[idx]).convert(\"RGB\")\n",
    "        boxes = self.bounding_boxes_minmax[idx]  # bounding_boxesはすでに各画像に対するバウンディングボックスのリスト\n",
    "       \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, boxes\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# バナナ画像が格納されているディレクトリ\n",
    "data_dir = \"bananas_images_train\"\n",
    "# 画像ファイル名をフルパスに変換するヘルパー関数\n",
    "def get_image_path(filename):\n",
    "    return data_dir+'/'+filename\n",
    "\n",
    "# データセットの作成\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = BananaDataset([get_image_path(filename) for filename in image_files], bounding_boxes_minmax, transform)\n",
    "\n",
    "\n",
    "# データローダーの作成\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# モデルのロード\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1ea3150d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1089, 623, 2135, 3048]\n",
      "[284, 569, 2933, 2667]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1017, 1413, 3086, 2637]\n",
      "[1519, 946, 3695, 2235]\n",
      "[1117, 1129, 2607, 1744]\n",
      "[0, 0, 0, 0]\n",
      "[1649, 384, 3086, 1898]\n",
      "[881, 863, 2702, 2111]\n",
      "[0, 0, 0, 0]\n",
      "[792, 1657, 2589, 2431]\n",
      "[1070, 1188, 2921, 2401]\n",
      "[1082, 928, 3051, 2057]\n",
      "[0, 0, 0, 0]\n",
      "[479, 514, 1762, 1519]\n",
      "[1862, 1188, 2601, 1892]\n",
      "[1041, 715, 3725, 2554]\n",
      "[0, 0, 0, 0]\n",
      "[656, 1106, 2944, 2578]\n",
      "[1276, 1077, 2050, 2643]\n",
      "[429, 1385, 2353, 3260]\n",
      "[1143, 738, 2262, 3405]\n",
      "[0, 0, 0, 0]\n",
      "[907, 1022, 1851, 3260]\n",
      "[1023, 1117, 3624, 2247]\n",
      "[0, 0, 0, 0]\n",
      "[2140, 225, 3512, 2448]\n",
      "[0, 0, 0, 0]\n",
      "[1077, 599, 1978, 2431]\n",
      "[733, 1017, 3287, 1992]\n",
      "[1685, 1419, 2607, 1821]\n",
      "[1709, 1431, 2489, 2241]\n",
      "[1413, 733, 2383, 1833]\n",
      "[1519, 603, 3482, 2530]\n",
      "[0, 0, 0, 0]\n",
      "[1638, 745, 3169, 2341]\n",
      "[1348, 1117, 2968, 2252]\n",
      "[1295, 1469, 2332, 2057]\n",
      "[625, 1863, 2339, 2754]\n",
      "[956, 1518, 1724, 3574]\n",
      "[865, 1137, 2038, 4016]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[934, 378, 3920, 1561]\n",
      "[822, 1194, 3139, 2270]\n",
      "[0, 0, 0, 0]\n",
      "[865, 1040, 2534, 2528]\n",
      "[1029, 1366, 2749, 2128]\n",
      "[479, 609, 1726, 2040]\n",
      "[0, 0, 0, 0]\n",
      "[1111, 863, 3754, 1945]\n",
      "[659, 593, 2455, 3943]\n",
      "[922, 881, 3695, 2028]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1283, 744, 3293, 2483]\n",
      "[1236, 834, 3234, 1856]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for images, targets in dataset:\n",
    "    print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4000e6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1029]), tensor([1366]), tensor([2749]), tensor([2128])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([1041]), tensor([715]), tensor([3725]), tensor([2554])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([284]), tensor([569]), tensor([2933]), tensor([2667])]\n",
      "[tensor([1236]), tensor([834]), tensor([3234]), tensor([1856])]\n",
      "[tensor([1638]), tensor([745]), tensor([3169]), tensor([2341])]\n",
      "[tensor([429]), tensor([1385]), tensor([2353]), tensor([3260])]\n",
      "[tensor([1685]), tensor([1419]), tensor([2607]), tensor([1821])]\n",
      "[tensor([625]), tensor([1863]), tensor([2339]), tensor([2754])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([656]), tensor([1106]), tensor([2944]), tensor([2578])]\n",
      "[tensor([922]), tensor([881]), tensor([3695]), tensor([2028])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([1111]), tensor([863]), tensor([3754]), tensor([1945])]\n",
      "[tensor([1519]), tensor([946]), tensor([3695]), tensor([2235])]\n",
      "[tensor([822]), tensor([1194]), tensor([3139]), tensor([2270])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([1070]), tensor([1188]), tensor([2921]), tensor([2401])]\n",
      "[tensor([1143]), tensor([738]), tensor([2262]), tensor([3405])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([934]), tensor([378]), tensor([3920]), tensor([1561])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([1519]), tensor([603]), tensor([3482]), tensor([2530])]\n",
      "[tensor([1089]), tensor([623]), tensor([2135]), tensor([3048])]\n",
      "[tensor([659]), tensor([593]), tensor([2455]), tensor([3943])]\n",
      "[tensor([1082]), tensor([928]), tensor([3051]), tensor([2057])]\n",
      "[tensor([479]), tensor([514]), tensor([1762]), tensor([1519])]\n",
      "[tensor([1117]), tensor([1129]), tensor([2607]), tensor([1744])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([2140]), tensor([225]), tensor([3512]), tensor([2448])]\n",
      "[tensor([1348]), tensor([1117]), tensor([2968]), tensor([2252])]\n",
      "[tensor([1023]), tensor([1117]), tensor([3624]), tensor([2247])]\n",
      "[tensor([1276]), tensor([1077]), tensor([2050]), tensor([2643])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([1862]), tensor([1188]), tensor([2601]), tensor([1892])]\n",
      "[tensor([792]), tensor([1657]), tensor([2589]), tensor([2431])]\n",
      "[tensor([1649]), tensor([384]), tensor([3086]), tensor([1898])]\n",
      "[tensor([1413]), tensor([733]), tensor([2383]), tensor([1833])]\n",
      "[tensor([479]), tensor([609]), tensor([1726]), tensor([2040])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([1077]), tensor([599]), tensor([1978]), tensor([2431])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([1017]), tensor([1413]), tensor([3086]), tensor([2637])]\n",
      "[tensor([1709]), tensor([1431]), tensor([2489]), tensor([2241])]\n",
      "[tensor([1283]), tensor([744]), tensor([3293]), tensor([2483])]\n",
      "[tensor([1295]), tensor([1469]), tensor([2332]), tensor([2057])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([865]), tensor([1137]), tensor([2038]), tensor([4016])]\n",
      "[tensor([881]), tensor([863]), tensor([2702]), tensor([2111])]\n",
      "[tensor([865]), tensor([1040]), tensor([2534]), tensor([2528])]\n",
      "[tensor([956]), tensor([1518]), tensor([1724]), tensor([3574])]\n",
      "[tensor([907]), tensor([1022]), tensor([1851]), tensor([3260])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n",
      "[tensor([733]), tensor([1017]), tensor([3287]), tensor([1992])]\n",
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n"
     ]
    }
   ],
   "source": [
    "for images, boxes in data_loader:\n",
    "    print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c7889849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boxes': tensor([[ 659.,  593., 2455., 3943.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1295., 1469., 2332., 2057.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1029., 1366., 2749., 2128.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1709., 1431., 2489., 2241.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 934.,  378., 3920., 1561.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 792., 1657., 2589., 2431.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1413.,  733., 2383., 1833.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1111.,  863., 3754., 1945.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[2140.,  225., 3512., 2448.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1082.,  928., 3051., 2057.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1041.,  715., 3725., 2554.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 822., 1194., 3139., 2270.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 656., 1106., 2944., 2578.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1023., 1117., 3624., 2247.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 733., 1017., 3287., 1992.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1685., 1419., 2607., 1821.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1649.,  384., 3086., 1898.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 865., 1040., 2534., 2528.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1519.,  946., 3695., 2235.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 907., 1022., 1851., 3260.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1236.,  834., 3234., 1856.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 625., 1863., 2339., 2754.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1276., 1077., 2050., 2643.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 881.,  863., 2702., 2111.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1089.,  623., 2135., 3048.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1283.,  744., 3293., 2483.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1143.,  738., 2262., 3405.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1862., 1188., 2601., 1892.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 284.,  569., 2933., 2667.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 479.,  609., 1726., 2040.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 865., 1137., 2038., 4016.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1070., 1188., 2921., 2401.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 922.,  881., 3695., 2028.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1638.,  745., 3169., 2341.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1017., 1413., 3086., 2637.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1348., 1117., 2968., 2252.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 429., 1385., 2353., 3260.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[ 956., 1518., 1724., 3574.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boxes': tensor([[ 479.,  514., 1762., 1519.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1117., 1129., 2607., 1744.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1519.,  603., 3482., 2530.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n",
      "{'boxes': tensor([[1077.,  599., 1978., 2431.]]), 'labels': tensor([1]), 'image_id': tensor([], size=(1, 0), dtype=torch.int64), 'area': tensor([], size=(1, 0)), 'iscrowd': tensor([], size=(1, 0), dtype=torch.int64)}\n"
     ]
    }
   ],
   "source": [
    "# デバイスの指定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# オプティマイザの設定\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "# 学習のループ\n",
    "for image_tensors, targets in data_loader:\n",
    "    image_tensors = list(image.to(device) for image in image_tensors)\n",
    "\n",
    "    # ターゲットの形式を正しく組み立てる\n",
    "    target_list = []\n",
    "\n",
    "    # ターゲットにバウンディングボックスが存在しない場合\n",
    "    if any(x == 0 for x in targets):\n",
    "        # デフォルトのバウンディングボックスをバインディングボックスとして渡す\n",
    "        # ここでは、適当な非ゼロ座標を設定します\n",
    "       continue;\n",
    "    else:\n",
    "        # バウンディングボックスをテンソルに変換\n",
    "        target_tensor = {\n",
    "            \"boxes\": torch.tensor([targets], dtype=torch.float32, device=device),\n",
    "            \"labels\": torch.tensor([1], dtype=torch.int64),\n",
    "            \"image_id\": torch.tensor([[]], dtype=torch.int64),\n",
    "            \"area\": torch.tensor([[]], dtype=torch.float32),\n",
    "            \"iscrowd\": torch.tensor([[]], dtype=torch.int64),\n",
    "        }\n",
    "        target_list.append(target_tensor)\n",
    "\n",
    "#     print(targets)\n",
    "#     print(\"------\")\n",
    "#     このモデルは物体が存在しない画像はのぞいて学習させた\n",
    "    optimizer.zero_grad()\n",
    "    loss_dict = model(image_tensors, target_list)\n",
    "    losses = sum(loss for loss in loss_dict.values())\n",
    "    losses.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eaf87dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# 1. 画像の前処理\n",
    "def preprocess_image(image):\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor(),  # 画像をテンソルに変換\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)  # バッチ次元を追加\n",
    "\n",
    "# 2. モデルに画像を渡して推論\n",
    "def predict(model, image_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        predictions = model(image_tensor)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# 3. バウンディングボックスを描画\n",
    "def draw_boxes(image, predictions, threshold=0.5):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for score, label, box in zip(predictions['scores'], predictions['labels'], predictions['boxes']):\n",
    "        if score > threshold:\n",
    "            box = [round(i, 2) for i in box.tolist()]  # バウンディングボックスの座標を整数に変換\n",
    "            draw.rectangle(box, outline=\"red\", width=3)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# 画像ファイルの読み込み\n",
    "image_path = 'bananas_images_test/b32.JPG'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# 画像の前処理\n",
    "image_tensor = preprocess_image(image)\n",
    "\n",
    "# モデルに画像を渡して推論\n",
    "predictions = predict(model, image_tensor)\n",
    "\n",
    "# バウンディングボックスを描画\n",
    "result_image = draw_boxes(image.copy(), predictions[0], threshold=0.5)\n",
    "\n",
    "# 結果の画像を表示\n",
    "result_image.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8141b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('bananaDetect1.pkl','wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b35795",
   "metadata": {},
   "source": [
    "#モデル性能向上に必要なこと \n",
    "1. batch_sizeを大きくする \n",
    "2. バナナが存在しない画像も学習できるようにする\n",
    "3. バナナ画像のバリデーションを増やす \n",
    "4. 学習させる画像を増やす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcfdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
